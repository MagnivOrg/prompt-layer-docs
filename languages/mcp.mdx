---
title: "MCP Server"
icon: "server"
---

[Model Context Protocol (MCP)](https://modelcontextprotocol.io/) is an open standard that lets AI assistants connect to external tools and data sources. The PromptLayer MCP server gives any MCP-compatible client — like Claude Desktop, Claude Code, or Cursor — direct access to your PromptLayer workspace.

This means you can manage prompt templates, run evaluations, log requests, and more, all through natural language in your AI coding assistant.

<Card title="GitHub Repository" icon="github" href="https://github.com/MagnivOrg/promptlayer-mcp">
  Setup instructions, full tool reference, and source code.
</Card>

## Why Use It?

- **Manage prompts from your editor** — publish new template versions, move release labels, and search templates without leaving your coding environment.
- **Run evaluations conversationally** — create reports, run pipelines, and check scores by asking your AI assistant.
- **Log and inspect requests** — track LLM calls, attach metadata and scores, all through natural language.
- **Works with any MCP client** — Claude Desktop, Claude Code, Cursor, or anything that supports the MCP standard.

## Quick Setup

You'll need a PromptLayer API key from your [dashboard](https://www.promptlayer.com/). Then add the server to your MCP client:

```bash
npx -y @promptlayer/mcp-server
```

For client-specific configuration (Claude Desktop, Cursor, etc.), see the [GitHub README](https://github.com/MagnivOrg/promptlayer-mcp#usage).

## Example

Once connected, you can ask your AI assistant things like:

- *"List all my prompt templates"*
- *"Publish a new version of my welcome-email template with this updated system prompt..."*
- *"Move the production label to version 3 of welcome-email"*
- *"Run an evaluation on my QA dataset"*

The assistant will call the appropriate PromptLayer tools automatically.
