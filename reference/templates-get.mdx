---
title: "Get Prompt Template"
openapi: "POST /prompt-templates/{prompt_name}"
---

Get a prompt template by `prompt_name`. You can optionally specify a `version` or `label` to get a specific version of the prompt template. If you do not specify a version or label, the latest version of the prompt template is returned. You can also optionally specify a `provider` to get llm-specific keyword arguments that you can directly pass to your llm client. You can also optionally specify `input_variables` which will actually format the prompt template with the input variables. For example,

<CodeGroup>
```bash REST
curl -X POST https://api.promptlayer.com/prompt-templates/{prompt_name} \
-H 'Content-Type: application/json' \
-H 'X-API-Key: {api_key}' \
-d '{"provider": "openai"}' | jq .llm_kwargs
```
</CodeGroup>
