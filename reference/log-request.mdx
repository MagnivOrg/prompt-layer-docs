---
title: "Log Request"
openapi: "POST /log-request"
---

Log a request to the system. This is useful for logging requests from custom LLM providers.

## Using Structured Outputs

When logging requests that use structured outputs (JSON schemas), include the schema configuration in the `parameters` field using the `response_format.json_schema` structure.

**Example:**

```json
{
  "provider": "openai",
  "model": "gpt-4",
  "api_type": "chat-completions"
  "parameters": {
    "temperature": 0.7,
    "response_format": {
      "type": "json_schema",
      "json_schema": {
        "name": "YourSchemaName",
        "schema": {
          "type": "object",
          "properties": {
            "field1": {"type": "string"}
          },
          "required": ["field1"]
        }
      }
    }
  }
}
```

For complete examples with OpenAI, Anthropic, Google Gemini, and detailed implementation guidance, see:

**[Logging Structured Outputs Guide →](/features/prompt-history/structured-output-logging)**

## Logging Tools (Function Definitions)

When logging requests that include tool/function definitions, include the tools array directly in the `input` field. This allows request replay to use the exact tools from the original request.

**Example:**

```json
{
  "provider": "openai",
  "model": "gpt-4o",
  "input": {
    "type": "chat",
    "messages": [
      {
        "role": "user",
        "content": [{"type": "text", "text": "What's the weather in NYC?"}]
      }
    ],
    "tools": [
      {
        "type": "function",
        "function": {
          "name": "get_weather",
          "description": "Get the current weather for a location",
          "parameters": {
            "type": "object",
            "properties": {
              "location": {
                "type": "string",
                "description": "City name"
              }
            },
            "required": ["location"]
          }
        }
      }
    ],
    "tool_choice": "auto"
  },
  "output": {
    "type": "chat",
    "messages": [
      {
        "role": "assistant",
        "content": [],
        "tool_calls": [
          {
            "id": "call_abc123",
            "type": "function",
            "function": {
              "name": "get_weather",
              "arguments": "{\"location\": \"NYC\"}"
            }
          }
        ]
      }
    ]
  },
  "request_start_time": "2024-04-03T20:57:25+00:00",
  "request_end_time": "2024-04-03T20:57:26+00:00"
}
```

### Tool Choice Options

You can control which tool the model should use with `tool_choice`:

- `"auto"` - Model decides whether to use a tool
- `"none"` - Model will not call any tools
- `"required"` - Model must call at least one tool
- `{"type": "function", "function": {"name": "get_weather"}}` - Force a specific tool

For logging tool call responses, see the [Custom Logging Guide](/features/prompt-history/custom-logging#working-with-tools-and-function-calls).

## Using Extended Thinking / Reasoning

When logging requests that use extended thinking (Anthropic), thinking mode (Google), or reasoning (OpenAI), the configuration must be passed inside the `parameters` field using provider-specific formats:

| Provider | Parameter | Example |
|----------|-----------|---------|
| Anthropic | `thinking` | `{"thinking": {"type": "enabled", "budget_tokens": 10000}}` |
| Google | `thinking_config` | `{"thinking_config": {"include_thoughts": true, "thinking_budget": 8000}}` |
| OpenAI | `reasoning_effort` | `{"reasoning_effort": "high"}` |

For complete examples with thinking content blocks and full code samples, see:

**[Logging Extended Thinking Guide →](/features/prompt-history/custom-logging#logging-extended-thinking-and-reasoning)**

## Error Tracking

You can log failed or problematic requests using the `status`, `error_type`, and `error_message` fields. This is useful for monitoring error rates, debugging issues, and tracking provider reliability.

### Example: Logging a Failed Request

```json
{
  "provider": "openai",
  "model": "gpt-4",
  "api_type": "chat-completions",
  "input": {
    "type": "chat",
    "messages": [{"role": "user", "content": "Hello"}]
  },
  "output": {
    "type": "chat",
    "messages": []
  },
  "request_start_time": "2024-01-15T10:30:00Z",
  "request_end_time": "2024-01-15T10:30:30Z",
  "status": "ERROR",
  "error_type": "PROVIDER_TIMEOUT",
  "error_message": "Request timed out after 30 seconds"
}
```

### Example: Logging a Warning

Use `WARNING` status for requests that succeeded but had issues (e.g., retries, degraded responses):

```json
{
  "provider": "anthropic",
  "model": "claude-3-sonnet",
  "api_type": "chat-completions",
  "input": {
    "type": "chat",
    "messages": [{"role": "user", "content": "Summarize this"}]
  },
  "output": {
    "type": "chat",
    "messages": [{"role": "assistant", "content": "Summary..."}]
  },
  "request_start_time": "2024-01-15T10:30:00Z",
  "request_end_time": "2024-01-15T10:30:05Z",
  "status": "WARNING",
  "error_type": "PROVIDER_RATE_LIMIT",
  "error_message": "Succeeded after 2 retries due to rate limiting"
}
```

## Related Documentation

- [Custom Logging Guide](/features/prompt-history/custom-logging) - General guide to logging requests
- [Structured Outputs in Prompt Registry](/features/prompt-registry/structured-outputs) - Creating prompts with structured outputs
- [Metadata Documentation](/features/prompt-history/metadata) - Using metadata for tracking