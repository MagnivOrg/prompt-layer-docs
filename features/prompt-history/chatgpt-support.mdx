---
title: "ChatGPT Support"
icon: "microchip-ai"
---

PromptLayer supports using ChatGPT in multiple ways

<CodeGroup>

```python Directly through the openai PromptLayer library
from promptlayer import openai
response = openai.ChatCompletion.create(
  model="gpt-3.5-turbo",
  messages=[
        {"role": "system", "content": "You are a helpful assistant."},
        {"role": "user", "content": "Who won the world series in 2020?"},
        {"role": "assistant", "content": "The Los Angeles Dodgers won the World Series in 2020."},
        {"role": "user", "content": "Where was it played?"}
    ]
)
```


```python Using LangChain LLM
from langchain.llms import PromptLayerOpenAIChat
llm = PromptLayerOpenAIChat()
resp = llm("tell me a joke")
```

 ```python Using LangChain chat model
from langchain.chat_models import PromptLayerChatOpenAI
from langchain.schema import (
    SystemMessage,
    HumanMessage,
)
chat = PromptLayerChatOpenAI(pl_tags=["langchain"])
chat([
  SystemMessage(content="You are a helpful assistant that translates English to French."),
  HumanMessage(content="Translate this sentence from English to French. I love programming.")
])
```
</CodeGroup>
    
   