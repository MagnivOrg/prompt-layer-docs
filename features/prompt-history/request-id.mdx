---
title: "Request IDs"
icon: "id-card"
---

Every PromptLayer log has a unique PromptLayer Request ID (`pl_id`). 

All tracking in PromptLayer is based on the `pl_request_id`. This identifier is needed to enrich logs with [metadata](/features/prompt-history/metadata), [scores](/features/prompt-history/scoring-requests), [associated prompt templates](/features/prompt-history/tracking-templates), and more.

You can quickly grab a request ID from the web UI as shown below.

<img src="/images/copy-request-id.gif" width="60%"/>

Specific instructions for retrieving the ID programmatically are below.

## REST API
The `pl_request_id` is returned as `request_id` in the case of a successful request when using the `REST api` with `/log-request`. This means that `request_id` will be a key in the object returned by a successful logged response.

[Learn more](/reference/log-request)

## Python

To retrieve the `pl_request_id` using OpenAI in Python (through `promptlayer_client.openai.OpenAI`), set the argument `return_pl_id` to `true` in your function call. This will change the call to now return the OpenAI response and the `pl_request_id`. If you are using `stream=true`, then only the last `pl_request_id` will be the id; otherwise, it will be `None`.

The same is true for Anthropic.
        
```python
from promptlayer import PromptLayer
promptlayer_client = PromptLayer()

OpenAI = promptlayer_client.openai.OpenAI
client = OpenAI()

response, pl_request_id = client.Completion.create(
    engine="gpt-3.5-turbo-instruct", 
    prompt="hi my name is ", 
    return_pl_id=True
)
```

## Javascript

To retrieve the `pl_request_id` using OpenAI in JavaScript (through `promptLayerClient.OpenAI`), set the argument `return_pl_id` to `true` in your function call. This will change the call to now return the OpenAI response and the `pl_request_id`. If you are using `stream: true`, then only the last `pl_request_id` will be the id; otherwise, it will be `undefined`.

The same is true for Anthropic.
        
```js
import { PromptLayer } from "promptlayer";
const promptLayerClient = new PromptLayer();

const OpenAI = promptLayerClient.OpenAI;
const client = new OpenAI();

const [response, pl_request_id] = await client.completions.create({
    model: "gpt-3.5-turbo-instruct",
    prompt: "hi my name is ",
    return_pl_id: true
});
```

