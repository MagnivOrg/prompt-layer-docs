---
title: "Multi-Turn Chat"
icon: "messages"
---

Building reliable conversational AI systems requires careful management of state and conversation history. This guide explains how to implement multi-turn chat using PromptLayer's stateless approach, which enhances reliability and makes your agents easier to test and debug.

## Why Stateless Turns?

Traditional conversational AI systems often maintain complex internal state, making them difficult to debug, test, and scale. The stateless approach treats each turn of the conversation as an independent, deterministic function that receives all necessary context through input variables.

### The Black Box Approach

The best way to build reliable conversational AI is to treat each turn as a black box. You provide inputs (conversation history, current query, available tools) and receive outputs (response, tool calls, next actions). This approach optimizes for rapid development and iteration - you're simply crafting prompts in natural language and validating outputs. By building your conversational system around this principle, you enable quick prompt iterations and fast feedback cycles, which are essential for developing robust multi-turn interactions.

The stateless approach particularly shines when it comes to systematic evaluation of conversation flows. For a deeper dive into evaluating multi-turn conversations, check out our blog post on [best practices for evaluating back-and-forth conversational AI](https://blog.promptlayer.com/best-practi-to-evaluate-back-and-forth-conversational-ai-in-promptlayer/).

## Implementation Pattern

Here's the core pattern for implementing stateless multi-turn chat:

```python
def run_conversation(user_question):
    chat_history = []
    ai_in_progress = []  # For handling multiple tool calls

    while True:
        # Each turn is stateless - all state passed via inputs
        # Using a prompt template (you can also use run_agent for more complex workflows)
        result = promptlayer_client.run(
            prompt_name="conversational-assistant",
            input_variables={
                "user_question": user_question,
                "chat_history": chat_history,
                "ai_in_progress": ai_in_progress
            },
            tags=["multi-turn-chat"]
        )

        # Extract the assistant's last message
        last_message = result["prompt_blueprint"]["prompt_template"]["messages"][-1]

        # Check if conversation should end
        if last_message.get("function_call", {}).get("name") == "end_conversation":
            return last_message

        # Handle tool calls
        if last_message.get("tool_calls"):
            tool_results = []
            for tool_call in last_message["tool_calls"]:
                tool_result = execute_tool(tool_call)
                tool_results.append({
                    "tool": tool_call["function"]["name"],
                    "result": tool_result
                })

            # Update ai_in_progress with tool results
            ai_in_progress.extend(tool_results)
        else:
            # Regular conversation turn - add to history
            chat_history.append({
                "role": "user",
                "content": [{"type": "text", "text": user_question}]
            })
            chat_history.append(last_message)

            # Get next user input (in real implementation)
            user_question = get_next_user_input()
            if not user_question:
                break

            # Clear ai_in_progress for next turn
            ai_in_progress = []

    return last_message
```

<Note>
You can also implement this pattern using agents for more complex workflows with multiple nodes and conditional logic. See [Running Agents](/running-requests/promptlayer-run-agent) for details on using `promptlayer_client.run_agent()`.
</Note>

## Designing Your Stateless Prompt

Your prompt template should be designed to receive all necessary state through input variables:

### Required Input Variables

1. **chat_history**: Array of previous messages in the conversation
2. **user_question**: The current user message or query
3. **ai_in_progress**: List of ongoing tool calls and their results (for handling tool execution)

### Using Message Placeholders

[Message Placeholders](/features/prompt-registry/placeholder-messages) are crucial for injecting conversation context into your prompts. They allow you to dynamically insert the conversation history into your prompt template:

```python
# In your prompt template, use a placeholder
# Role: placeholder
# Content: {{chat_history}}

# When calling the prompt
promptlayer_client.run(
    prompt_name="stateless-chat-assistant",
    input_variables={
        "chat_history": [
            {
                "role": "user",
                "content": [{"type": "text", "text": "What's the weather?"}]
            },
            {
                "role": "assistant",
                "content": [{"type": "text", "text": "I'll check the weather for you."}]
            }
        ],
        "user_question": "How about tomorrow?",
        "ai_in_progress": []
    }
)
```

## Handling Tool Calls

For agents that use tools, maintain tool state externally:

```python
def handle_tool_execution(agent_response, tool_registry):
    """Execute tools and prepare results for next turn"""

    if not agent_response.get("tool_calls"):
        return None

    tool_results = []
    for call in agent_response["tool_calls"]:
        tool = tool_registry.get(call["name"])
        if tool:
            result = tool.execute(call["arguments"])
            tool_results.append({
                "tool": call["name"],
                "call_id": call["id"],
                "result": result
            })

    return tool_results
```

## Best Practices

### 1. Keep History Manageable
Implement a sliding window or summarization strategy to prevent context from growing too large:

```python
def truncate_history(history, max_turns=10):
    """Keep only the most recent N turns"""
    if len(history) > max_turns:
        # Optionally summarize older turns
        summary = summarize_old_turns(history[:-max_turns])
        return [{"role": "system", "content": summary}] + history[-max_turns:]
    return history
```

### 2. Structure Your State
Use consistent structures for passing state:

```python
class ConversationState:
    def __init__(self):
        self.history = []
        self.context = {}
        self.tool_results = []

    def to_input_variables(self):
        """Convert to format expected by agent"""
        return {
            "conversation_history": self.history,
            "context": self.context,
            "pending_tools": self.tool_results
        }
```

### 3. Test Individual Turns
Since each turn is stateless, you can easily test specific scenarios:

```python
def test_weather_query_with_history():
    """Test how agent responds to weather query with context"""

    test_history = [
        {
            "role": "user",
            "content": [{"type": "text", "text": "I'm in New York"}]
        },
        {
            "role": "assistant",
            "content": [{"type": "text", "text": "Got it, you're in New York."}]
        }
    ]

    result = promptlayer_client.run(
        prompt_name="weather-assistant",
        input_variables={
            "chat_history": test_history,
            "user_question": "What's the weather like?",
            "ai_in_progress": []
        }
    )

    last_message = result["prompt_blueprint"]["prompt_template"]["messages"][-1]
    assert "New York" in last_message["content"][0]["text"]
```

## Integration with Evaluation

The stateless approach makes it easy to evaluate your conversational AI:

1. **Record real conversations** as sequences of inputs and outputs
2. **Replay conversations** with modified parameters to test variations
3. **Evaluate individual turns** for quality and correctness
4. **Test edge cases** by crafting specific conversation states

Learn more about setting up comprehensive evaluations in our [Evaluation and Ranking](/why-promptlayer/evaluation-and-ranking) guide.

## Example: Customer Support Agent

Here's a complete example of a stateless customer support agent:

```python
class StatelessSupportAgent:
    def __init__(self, promptlayer_client):
        self.client = promptlayer_client
        self.max_turns = 20

    def run_conversation(self, initial_question):
        chat_history = []
        ai_in_progress = []
        user_question = initial_question
        turn_count = 0

        while turn_count < self.max_turns:
            # Run stateless turn
            result = self.client.run(
                prompt_name="support-agent",
                input_variables={
                    "chat_history": chat_history,
                    "user_question": user_question,
                    "ai_in_progress": ai_in_progress,
                    "user_context": self.get_user_context()
                },
                tags=["support", "multi-turn"]
            )

            # Extract assistant's response
            last_message = result["prompt_blueprint"]["prompt_template"]["messages"][-1]

            # Check for conversation end
            if last_message.get("function_call", {}).get("name") == "end_conversation":
                return self.format_final_response(last_message)

            # Handle tool calls
            if last_message.get("tool_calls"):
                tool_results = []
                for tool_call in last_message["tool_calls"]:
                    tool_result = self.execute_tool(tool_call)
                    tool_results.append({
                        "tool": tool_call["function"]["name"],
                        "result": tool_result
                    })
                ai_in_progress.extend(tool_results)
            else:
                # Add messages to history
                chat_history.append({
                    "role": "user",
                    "content": [{"type": "text", "text": user_question}]
                })
                chat_history.append(last_message)

                # Get next user input
                user_question = self.get_next_user_input()
                if not user_question:
                    break

                # Clear ai_in_progress for next turn
                ai_in_progress = []

            turn_count += 1

        return self.handle_max_turns_reached(chat_history)
```

## Next Steps

- Explore [Message Placeholders](/features/prompt-registry/placeholder-messages) for dynamic prompt construction
- Set up [Evaluations](/why-promptlayer/evaluation-and-ranking) for your conversational flows
- Learn about [Agent development](/why-promptlayer/agents) for complex workflows