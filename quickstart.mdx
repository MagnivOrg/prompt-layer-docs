---
title: "Quickstart"
icon: "flag-checkered"
---

Get started using PromptLayer in minutes.

- Create and version prompts visually
- Programmatically retrieve and iterate on prompts
- Log and evaulate prompt versions

First, make sure you have signed up for an account at www.promptlayer.com to begin üç∞

## Create your first prompt template

PromptLayer makes creating, versioning, and collaborating on prompt templates easy. They are model-agnostic and auditable.

1. From [PromptLayer's home screen](https://www.promptlayer.com), navigate to the prompt registry ([read more](/features/prompt-registry/overview)).
2. Click "Create Template" to create a new prompt template.

![Find Registry](/images/quickstart/find-registry.png)

For this example, let's create a new prompt template called "ai-poet":

```
You are a skilled poet specializing in haiku. 

Your task is to write a haiku based on a topic provided by the user. 

The haiku must have 17 syllables.
Structured in three lines of 5, 7, and 5 syllables respectively. 
```

Next, add a new message with an input variable `{topic}`. This will be filled out by user input when interacting with the AI.

![Haiku Prompt](/images/quickstart/haiku-prompt.png)

## Set Up PromptLayer Locally

### Install PromptLayer & OpenAI

Install the required packages:

```
pip install promptlayer
pip install openai
```

Ensure you have the latest versions if already installed.

### API Key Env Var Setup

1. Retrieve your [OpenAI API key](https://platform.openai.com/api-keys)
2. Get a PromptLayer API key from settings (_click the cog on the top right_). 
3. Create a .env file with the following:

```
OPENAI_API_KEY=sk-<your_openai_api_key>
PROMPTLAYER_API_KEY=<your_promptlayer_api_key>
```
For more on setting up environment variables in Python, refer to this [guide](https://www.twilio.com/en-us/blog/environment-variables-python).

We recommend using `python-dotenv`:

```
pip install python-dotenv
```

Create a Python file and load the environment variables:

``` Python
from dotenv import load_dotenv

load_dotenv()  # Load env vars from .env file
```

### Import PromptLayer

This quickstart uses OpenAI, but PromptLayer supports most major LLM providers (Anthropic, LLama, Google, Cohere, Mistral, etc).

<CodeGroup>

```python Python
import promptlayer
OpenAI = promptlayer.openai.OpenAI
client = OpenAI()
```


```js JavaScript
import { promptlayer } from "promptlayer";
const OpenAI = promptlayer.OpenAI;
const client = new OpenAI();
```

</CodeGroup>
    
## Retrieve the Prompt

Pull down the prompt template with one line:
``` Python
ai_poet_prompt = promptlayer.templates.get("ai-poet")
```

Or specify a [release label](/features/prompt-registry/overview#release-labels) for prod/staging environments. First, make sure to add the release label "prod" in the PromptLayer dashboard.
``` Python
ai_poet_prompt = promptlayer.templates.get("ai-poet", {
  "label": "prod"
})
```

### Inject Input Variables

Remember the `{topic}` user input variable to specify the haiku topic in our prompt? PromptLayer can format the f-string or Jinja2 template using this variable.

Add an argument to inject input variables. For example:

``` Python
input_variables = {
    "topic": "The American Revolution"
}

# Grab the prompt template
ai_poet_prompt = promptlayer.templates.get("ai-poet",
{
  "input_variables": input_variables
})
```

### Run the Request

PromptLayer can help format the prompt to send to OpenAI:

``` Python
input_variables = {
    "topic": "American History"
}

# Grab the prompt template
ai_poet_prompt = promptlayer.templates.get("ai-poet",
{
  "input_variables": input_variables,
  "provider": "openai", # Format for OpenAI
})

response = client.chat.completions.create(
  **ai_poet_prompt['llm_kwargs'],
  model="gpt-3.5-turbo", 
)
print("Answer:", response.choices[0].text)
```

### Logs

Open the dashboard to see the logs.
[image]

#### Extra logs

Add more metadata to each log, such as the prompt template, input variables, and score:

``` Python
input_variables = {
    "topic": "American History"
}

# Grab the prompt template
ai_poet_prompt = promptlayer.templates.get("ai-poet",
{
  "input_variables": input_variables,
  "provider": "openai",
})

response, pl_request_id = client.chat.completions.create(
  **city_choice_prompt['llm_kwargs'],
  model="gpt-3.5-turbo", # Alternatively specify this in the dashboard
  pl_tags=["quickstart_tutorial"], # Optionally add a tag
  return_pl_id=True
)
print("Answer:", response.choices[0].text)

# Associate the request with the prompt template used
promptlayer.track.prompt(request_id=pl_request_id, 
    prompt_name='ai-poet', prompt_input_variables=input_variables)
  
# Add metadata to the logs
promptlayer.track.metadata(request_id=pl_request_id, metadata={
  "user_id": "abc123"
})

# Add a score to the log
promptlayer.track.score(
    request_id=pl_request_id,
    score=100,
)
```

This helps triage through error logs when using [advanced search](/why-promptlayer/advanced-search), creating [datasets](/features/evaluations/datasets), or [fine-tuning](/why-promptlayer/fine-tuning).

### No more redeploys!

Every time you update the prompt in the dashboard, re-run the code and it will grab the latest version. No eng redeploy is needed.


![Redeploy Gif](/images/quickstart/redeploy.gif)

## Analytics

Visit the dashboard to see analytics.
![Analytics Screenshot](/images/quickstart/analytics-screenshot.png)

## Evaluations

Each time you edit the prompt version, you can run an evaluation. Learn more about evaluations [here](/features/evaluations/examples).

![Eval Scores](/images/quickstart/eval-scores.png)

# Further reading

From the docs:
- [Getting Started Tutorial](/getting_started)
- Migration Guide
- [Why use a prompt CMS?](/why-promptlayer/prompt-cms)
- [Evaluating Prompts with PromptLayer](/features/evaluations/examples)

From our blog:
- [Prompt Management and Collaboration](https://blog.promptlayer.com/scalable-prompt-management-and-collaboration-fff28af39b9b)
- [Our Favorite Prompts from our Prompt Engineering Tournament](https://blog.promptlayer.com/our-favorite-prompts-from-the-tournament-b9d99464c1dc)
- [Youtube LLM Development Tutorial Series](https://www.youtube.com/watch?v=u4LMdo-2EP4&list=PL6gx4Cwl9DGDLqIXStz_Zrk2utoTgrsfW)
- [Building ChatGPT from Scratch with PromptLayer](https://blog.promptlayer.com/building-chatgpt-from-scratch-the-right-way-ef82e771886e)
- [Comparing Prompts Across Different Models](https://blog.promptlayer.com/migrating-prompts-to-open-source-models-c21e1d482d6f)
- [Prompt Routers and Modular Prompt Architecture](https://blog.promptlayer.com/prompt-routers-and-modular-prompt-architecture-8691d7a57aee)

